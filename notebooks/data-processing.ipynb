{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import data,io,img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    raw_data_path = os.path.join(os.path.pardir,'data','raw')\n",
    "    train_data_path = os.path.join(raw_data_path,'train.csv')\n",
    "    depth_data_path = os.path.join(raw_data_path,'depths.csv')\n",
    "    df_train = pd.read_csv(train_data_path,index_col='id')\n",
    "    df_train.rle_mask.fillna(-1,inplace=True)\n",
    "    df_depth = pd.read_csv(depth_data_path,index_col='id')\n",
    "    df_train['depth'] = df_depth['z']\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,10)\n",
    "plt.hist(df['depth'].values,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=['000e218f21','0b73b427d1','0ba541766e','0a7e067255','0a1742c740']\n",
    "raw_data_path = os.path.join(os.path.pardir,'data','raw')\n",
    "train_images_path = os.path.join(raw_data_path,'train','images')\n",
    "train_masks_path = os.path.join(raw_data_path,'train','masks')\n",
    "plt.rcParams[\"figure.figsize\"] = (40,3)\n",
    "for i,imgname in enumerate(ids):  \n",
    "    img = mpimg.imread(train_images_path + '\\\\' + imgname + '.png')\n",
    "    img_mask = mpimg.imread(train_masks_path + '\\\\' + imgname + '.png')\n",
    "    plt.subplot(1,(len(ids)+1)*2,(i+1)*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,(len(ids)+1)*2,(i+1)*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image & convert into numpy\n",
    "\n",
    "def resizeimage(img,targetSize):\n",
    "    return resize(img, (targetSize, targetSize), mode='constant', preserve_range=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image file and convert into numpy array\n",
    "def convertImage2Array(imgname,rawpath):\n",
    "    image = io.imread(rawpath + '\\\\' + imgname + '.png',as_gray=True)\n",
    "    #resize and normalize data\n",
    "    resizedImage = resizeimage(image,128)\n",
    "    return np.array(img_as_float(resizedImage))\n",
    "\n",
    "train_images_path = os.path.join(raw_data_path,'train','images')\n",
    "df['image'] = [convertImage2Array(imgname,train_images_path) for imgname in df.index.values]\n",
    "\n",
    "train_masks_path = os.path.join(raw_data_path,'train','masks')\n",
    "df['mask_img'] = [convertImage2Array(imgname,train_masks_path) for imgname in df.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    # 128 -> 64\n",
    "    conv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = tf.keras.layers.Dropout(0.25)(pool1)\n",
    "\n",
    "    # 64 -> 32\n",
    "    conv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = tf.keras.layers.Dropout(0.5)(pool2)\n",
    "\n",
    "    # 32 -> 16\n",
    "    conv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = tf.keras.layers.Dropout(0.5)(pool3)\n",
    "\n",
    "    # 16 -> 8\n",
    "    conv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = tf.keras.layers.Dropout(0.5)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    convm = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
    "\n",
    "    # 8 -> 16\n",
    "    deconv4 = tf.keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = tf.keras.layers.concatenate([deconv4, conv4])\n",
    "    uconv4 = tf.keras.layers.Dropout(0.5)(uconv4)\n",
    "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    # 16 -> 32\n",
    "    deconv3 = tf.keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = tf.keras.layers.concatenate([deconv3, conv3])\n",
    "    uconv3 = tf.keras.layers.Dropout(0.5)(uconv3)\n",
    "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    # 32 -> 64\n",
    "    deconv2 = tf.keras.layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = tf.keras.layers.concatenate([deconv2, conv2])\n",
    "    uconv2 = tf.keras.layers.Dropout(0.5)(uconv2)\n",
    "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    # 64 -> 128\n",
    "    deconv1 = tf.keras.layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = tf.keras.layers.concatenate([deconv1, conv1])\n",
    "    uconv1 = tf.keras.layers.Dropout(0.5)(uconv1)\n",
    "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "\n",
    "    uncov1 = tf.keras.layers.Dropout(0.5)(uconv1)\n",
    "    output_layer = tf.keras.layers.Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "img_size_target = 128\n",
    "input_layer = tf.keras.Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input_layer,output_layer)\n",
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train & test splitt\n",
    "\n",
    "ids_train,ids_valid,X_train,X_valid,y_train,y_valid,depth_train,depth_valid = train_test_split(\n",
    "    df.index.values.tolist(),\n",
    "    np.array(df.image.values.tolist()).reshape(-1,128,128,1),\n",
    "    np.array(df.mask_img.values.tolist()).reshape(-1,128,128,1),\n",
    "    df.depth.values,\n",
    "    test_size=0.2\n",
    "    )\n",
    "\n",
    "X_train = np.append(X_train, [np.fliplr(x) for x in X_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10,verbose=1)\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint('./keras.model', save_best_only=True)\n",
    "board = keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "#Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "history = model.fit(X_train,y_train,validation_data=[X_valid,y_valid],batch_size=batch_size,epochs=epochs,callbacks=[early_stopping,check_point,board,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
